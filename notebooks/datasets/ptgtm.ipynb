{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Platinum group metals dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pgm.tar.bz2', <http.client.HTTPMessage at 0x104894c88>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://journals.aps.org/prx/supplemental/10.1103/PhysRevX.3.041035/pgm.tar.bz2'\n",
    "urllib.request.urlretrieve(url, 'pgm.tar.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The parser, and the writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Parser(object):\n",
    "    def __init__(self, aflowout_file, contcar_file):\n",
    "        pairs = [x.strip() for x in aflowout_file.read().decode('ascii').split('|')]\n",
    "        self.properties = {}\n",
    "        for pair in pairs:\n",
    "            name, value = pair.split('=')\n",
    "            self.properties[name] = value\n",
    "\n",
    "        contcar_file.readline()\n",
    "        scaling = float(contcar_file.readline().decode('ascii'))\n",
    "        latt1 = [float(x)*scaling for x in contcar_file.readline().decode('ascii').strip().split()]\n",
    "        latt2 = [float(x)*scaling for x in contcar_file.readline().decode('ascii').strip().split()]\n",
    "        latt3 = [float(x)*scaling for x in contcar_file.readline().decode('ascii').strip().split()]\n",
    "        contcar_file.readline()\n",
    "        assert contcar_file.readline().decode('ascii').strip() == 'Direct'\n",
    "\n",
    "        compounds = self['compound']\n",
    "        atoms = []\n",
    "        for z, i in re.findall(r'([a-zA-Z]+)(\\d*)', compounds):\n",
    "            for j in range(int(i) if len(i) else 1):\n",
    "                atoms.append(z)\n",
    "        pos = []\n",
    "\n",
    "        for i in range(len(atoms)):\n",
    "            pos.append([float(x) for x in contcar_file.readline().decode('ascii').strip().split()])\n",
    "\n",
    "        self.properties['basis_vectors'] = [latt1, latt2, latt3]\n",
    "        self.properties['atoms'] = []\n",
    "        for pos, label in zip(pos, atoms):\n",
    "            self.properties['atoms'].append((label, pos))\n",
    "\n",
    "        try:\n",
    "            for pos_outf, atom in zip(self['positions'].split(';'), self['atoms']):\n",
    "                pos_calculated = atom[1]\n",
    "                coord = numpy.array([float(x) for x in pos_outf.split(',')[1:]]).flatten()\n",
    "                coord_calculated = numpy.dot(numpy.array(self['basis_vectors']).T,\n",
    "                                                numpy.array(pos_calculated)).flatten()\n",
    "                assert numpy.allclose(coord, coord_calculated, atol=3e-2)\n",
    "        except AssertionError as e:\n",
    "            print(self.properties)\n",
    "            raise e\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.properties[item]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in self.properties.items():\n",
    "            yield i\n",
    "\n",
    "    def get_json(self):\n",
    "        return {\n",
    "            'basis_matrix': self['basis_vectors'],\n",
    "            'atom_labels': [x[0] for x in self['atoms']],\n",
    "            'atom_positions_fractional': numpy.array([x[1] for x in self['atoms']]).tolist(),\n",
    "\n",
    "            'enthalpy_formation': float(self['enthalpy_formation']),\n",
    "            'enthalpy_formation_atom': float(self['enthalpy_formation_atom']),\n",
    "            \n",
    "            'calculation_details': self.properties\n",
    "        }\n",
    "\n",
    "def convert_to_txt(data, txt_fn):\n",
    "    output_str = []\n",
    "    for nth, i in enumerate(data):\n",
    "        output_str.append('--- %d ---' % (nth+1))\n",
    "        output_str.append('Formation enthalpy (eV): %f' % i['enthalpy_formation'])\n",
    "        output_str.append('Cell Volume: %f' % numpy.dot(numpy.cross(i['basis_matrix'][0], i['basis_matrix'][1]), i['basis_matrix'][2]))\n",
    "        output_str.append('Coordinates:')\n",
    "        for cord in i['atom_positions_fractional']:\n",
    "            output_str.append('%f %f %f' % tuple(cord))\n",
    "        output_str.append('Cell:')\n",
    "        for cord in i['basis_matrix']:\n",
    "            output_str.append('%f %f %f' % tuple(cord))\n",
    "        output_str.append('Atoms:')\n",
    "        output_str.append(' '.join(i['atom_labels']))\n",
    "        output_str.append('Calculation Details:')\n",
    "        output_str.append(json.dumps(i['calculation_details']))\n",
    "    f = open(txt_fn, 'w')\n",
    "    f.write('\\n'.join(output_str))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset in tar format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = tarfile.open('pgm.tar.bz2')\n",
    "all_files = data_file.getmembers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert bz2 to XYZ-like format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 39200 files.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "all_calculations = collections.defaultdict(lambda : [])\n",
    "\n",
    "processed = 0\n",
    "for file_info in all_files:\n",
    "    if file_info.isfile() and 'aflowlib_entry.out' in file_info.name:\n",
    "        system_name = file_info.name.split('/')[0]\n",
    "        contcar_fn = os.path.join(os.path.dirname(file_info.name), 'CONTCAR.relax.bz2')\n",
    "\n",
    "        aflowout_file = data_file.extractfile(file_info)\n",
    "        contcar_file = data_file.extractfile(contcar_fn)\n",
    "        aflowout_file = bz2.BZ2File(aflowout_file, 'r')\n",
    "        contcar_file = bz2.BZ2File(contcar_file, 'r')\n",
    "        \n",
    "        all_calculations[system_name].append(\n",
    "            Parser(aflowout_file, contcar_file).get_json()\n",
    "        )\n",
    "\n",
    "        processed += 1\n",
    "        if processed % 100 == 0:\n",
    "            clear_output()\n",
    "            print('Processed', processed, 'files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('Data/'):\n",
    "    os.mkdir('Data/')\n",
    "for key, value in all_calculations.items():\n",
    "    convert_to_txt(value, 'Data/%s.txt' % key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    cd Data\n",
    "    zip -9 ptgtm.zip *.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
